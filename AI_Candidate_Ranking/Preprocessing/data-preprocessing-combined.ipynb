{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11499479,"sourceType":"datasetVersion","datasetId":7209104}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-22T05:14:43.330545Z","iopub.execute_input":"2025-04-22T05:14:43.330804Z","iopub.status.idle":"2025-04-22T05:14:43.711555Z","shell.execute_reply.started":"2025-04-22T05:14:43.330776Z","shell.execute_reply":"2025-04-22T05:14:43.710790Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/resume-dataset-for-resume-ranking-group-10/resume_data.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Converting the degree_names into desired format","metadata":{}},{"cell_type":"code","source":"# Second method (using aliases)\n\nimport re\n\n# Mapping canonical degree to various common forms\n# EDUCATION_ALIASES = {\n#     \"phd\": [\"doctor of philosophy\", \"ph.d\", \"doctorate\"],\n#     \"mba\": [\"master of business administration\", \"mba executive\"],\n#     \"bsc\": [\"bachelor of science\", \"b.sc\", \"b.s\"],\n#     \"msc\": [\"master of science\", \"m.sc\", \"m.s\"],\n#     \"ba\": [\"bachelor of arts\"],\n#     \"ma\": [\"master of arts\"],\n#     \"bcom\": [\"bachelor of commerce\", \"b.com\"],\n#     \"mcom\": [\"master of commerce\", \"m.com\"],\n#     \"be\": [\"bachelor of engineering\", \"b.e\", \"b.eng\"],\n#     \"me\": [\"master of engineering\", \"m.e\", \"m.eng\"],\n#     \"bba\": [\"bachelor of business administration\"],\n#     \"mtech\": [\"master of technology\"],\n#     \"btech\": [\"bachelor of technology\"],\n#     \"diploma\": [\"technical diploma\", \"associate diploma\", \"polytechnic diploma\"],\n#     \"high school\": [\"high school diploma\", \"gce o-level\", \"ged\", \"gce a-level\"],\n# }\nEDUCATION_ALIASES = {\n    \"phd\": [\"doctor of philosophy\", \"ph.d\", \"ph.d.\", \"phd\", \"doctorate\", \"ph.d. in\", \"phd candidate\"],\n    \"mba\": [\"master of business administration\", \"mba executive\", \"executive mba\", \"mba\", \"masters of business administration\"],\n    \"msc\": [\"master of science\", \"m.sc\", \"m.s\", \"masters of science\", \"msc\", \"masters in science\", \"m.sc.\"],\n    \"ma\": [\"master of arts\", \"m.a\", \"m.a.\", \"masters of arts\"],\n    \"mcom\": [\"master of commerce\", \"m.com\", \"mcom\"],\n    \"me\": [\"master of engineering\", \"m.e\", \"m.eng\", \"m.e.\", \"m.engg\"],\n    \"mtech\": [\"master of technology\", \"m.tech\", \"mtech\", \"mtech integrated\"],\n    \"bsc\": [\"bachelor of science\", \"b.sc\", \"b.s\", \"bsc\", \"b.sc.\", \"b.s.\", \"honours bachelor of science\", \"bachelors of science\"],\n    \"ba\": [\"bachelor of arts\", \"b.a\", \"ba\", \"b.a.\", \"bachelors of arts\"],\n    \"bcom\": [\"bachelor of commerce\", \"b.com\", \"bcom\"],\n    \"be\": [\"bachelor of engineering\", \"b.e\", \"b.e.\", \"b.eng\", \"b.engg\", \"bachelor of engineering (b.e\"],\n    \"btech\": [\"bachelor of technology\", \"b.tech\", \"b.tech.\", \"btech\", \"b.tech(computers)\", \"dual degree (b.tech + m.tech)\", \"integrated b.tech & m.tech\"],\n    \"bba\": [\"bachelor of business administration\", \"b.b.a\", \"bba\", \"bba - accounting\", \"bba - finance\", \"bachelor business administration\"],\n    \"bca\": [\"bachelor of computer applications\", \"b.c.a\", \"bca\"],\n    \"mca\": [\"master of computer applications\", \"m.c.a\", \"mca\"],\n    \"bs\": [\"bs\", \"b.s\", \"b.s.\", \"b.s in\", \"bachelor's degree in science\", \"bachelor's in science\"],\n    \"ms\": [\"ms\", \"m.s\", \"m.s.\", \"master in computer science\", \"masters of science in information technology\"],\n    \"aa\": [\"associate of arts\", \"a.a\", \"aa\"],\n    \"aas\": [\"associate of applied science\", \"a.a.s\", \"aas\"],\n    \"as\": [\"associate of science\", \"a.s\", \"as\", \"associate of science degree\"],\n    \"associate\": [\"associate's degree\", \"associate degree\", \"associates degree\", \"associates\", \"associate\"],\n    \"diploma\": [\"technical diploma\", \"associate diploma\", \"polytechnic diploma\", \"diploma\", \"general diploma\", \"pg diploma\", \"master's diploma\"],\n    \"high school\": [\"high school diploma\", \"ged\", \"grade 12\", \"xii\", \"x\", \"kcse\"],\n    \"certificate\": [\"certificate of completion\", \"graduate certificate\", \"business certification\", \"epa certification\", \"aws brazing certification\", \"skills\", \"course\", \"certification\", \"minor\", \"training\", \"coaching\"],\n    \"others\": [\"n/a\", \"select one\", \"attending\", \"testing computer software\", \"general courses\"],\n\n    # Education levels that are more common in the Sri Lankan context\n    \"al\": [\"advanced level\", \"a/l\", \"a.l\", \"gce a/l\", \"gce advanced level\", \"gce (a/l)\", \"gce(al)\", \"gce-a/l\"],\n    \"ol\": [\"ordinary level\", \"o/l\", \"o.l\", \"gce o/l\", \"gce ordinary level\", \"gce (o/l)\", \"gce(ol)\", \"gce-o/l\"],\n    \"nvq\": [\"nvq\", \"nvq level 3\", \"nvq level 4\", \"nvq level 5\", \"nvq level 6\", \"national vocational qualification\", \"nvq diploma\"],\n    \"hnd\": [\"hnd\", \"higher national diploma\", \"hnd in\", \"higher national diploma in\"],\n    \"cima\": [\"cima\", \"chartered institute of management accountants\", \"cima qualification\"],\n    \"acca\": [\"acca\", \"association of chartered certified accountants\"],\n    \"ca\": [\"chartered accountant\", \"institute of chartered accountants of sri lanka\", \"ica\", \"ca sri lanka\"],\n    \"slim\": [\"slim\", \"slim diploma\", \"sri lanka institute of marketing\", \"slim pgd\"],\n    \"nibt\": [\"nibt\", \"national institute of business & technology\", \"nibt diploma\"],\n    \"bit\": [\"bit\", \"bachelor of information technology\", \"bit degree\", \"bit (colombo university)\"]\n\n}\n\n# Ranking the levels (higher number = higher qualification)\n# EDUCATION_RANKS = {\n#     \"high school\": 0,\n#     \"diploma\": 2,\n#     \"bsc\": 3,\n#     \"ba\": 3,\n#     \"be\": 3,\n#     \"bcom\": 3,\n#     \"bba\": 3,\n#     \"btech\": 3,\n#     \"msc\": 4,\n#     \"ma\": 4,\n#     \"mba\": 4,\n#     \"mtech\": 4,\n#     \"me\": 4,\n#     \"phd\": 5\n# }\nEDUCATION_RANKS = {\n    \"others\": 0,\n    \n    \"high school\": 1,\n    \"certificate\": 1,\n    \"ol\": 1,\n    \n    \"al\": 2,\n    \n    \"diploma\": 3,\n    \"associate\": 3,\n    \"nvq\": 3,\n    \"hnd\": 3,\n    \"aa\": 3,\n    \"aas\": 3,\n    \"as\": 3,\n    \"slim\": 3,  \n    \"nibt\": 3,   \n    \n    \"bsc\": 4,\n    \"bs\": 4,\n    \"ba\": 4,\n    \"be\": 4,\n    \"btech\": 4,\n    \"bit\": 4,    \n    \"cima\": 4,   \n    \"acca\": 4,      \n    \"bcom\": 4,\n    \"bba\": 4,\n    \"bca\": 4,\n    \n    \"msc\": 5,\n    \"ms\": 5,\n    \"ma\": 5,\n    \"me\": 5,\n    \"mtech\": 5,\n    \"mcom\": 5,\n    \"mba\": 5,\n    \"mca\": 5,\n    \"ca\": 5,\n    \n    \"phd\": 6\n}\n\n# Flattenning the aliases for easy reverse lookup\nFLATTENED_ALIASES = {}\nfor canonical, synonyms in EDUCATION_ALIASES.items():\n    for synonym in synonyms:\n        FLATTENED_ALIASES[synonym.lower()] = canonical\n\n\ndef get_highest_education(degree_entries):\n    if not isinstance(degree_entries, list):\n        degree_entries = [degree_entries]\n\n    best_match = (\"unknown\", -1)\n\n    for entry in degree_entries:\n        if not isinstance(entry, str):\n            continue\n\n        # Clean and normalize text\n        text = re.sub(r'[^\\w\\s]', '', entry.lower())\n\n        # Try matching from aliases\n        for synonym, canonical in FLATTENED_ALIASES.items():\n            if synonym in text:\n                rank = EDUCATION_RANKS.get(canonical, -1)\n                if rank > best_match[1]:\n                    best_match = (canonical, rank)\n\n        # Fallback to direct canonical keyword matching\n        for canonical, rank in EDUCATION_RANKS.items():\n            if canonical in text:\n                if rank > best_match[1]:\n                    best_match = (canonical, rank)\n\n    return best_match[1]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['highest_degree'] = df['degree_names'].apply(get_highest_education)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Educational Requirements","metadata":{}},{"cell_type":"code","source":"import re\n\n# Mapping canonical degree to various common forms\nEDUCATION_ALIASES = {\n    \"phd\": [\"doctor of philosophy\", \"ph.d\", \"ph.d.\", \"phd\", \"doctorate\", \"ph.d. in\", \"phd candidate\"],\n    \"mba\": [\"master of business administration\", \"mba executive\", \"executive mba\", \"mba\", \"masters of business administration\"],\n    \"msc\": [\"master of science\", \"m.sc\", \"m.s\", \"masters of science\", \"msc\", \"masters in science\", \"m.sc.\"],\n    \"ma\": [\"master of arts\", \"m.a\", \"m.a.\", \"masters of arts\"],\n    \"mcom\": [\"master of commerce\", \"m.com\", \"mcom\"],\n    \"me\": [\"master of engineering\", \"m.e\", \"m.eng\", \"m.e.\", \"m.engg\"],\n    \"mtech\": [\"master of technology\", \"m.tech\", \"mtech\", \"mtech integrated\"],\n    \"bsc\": [\"bachelor of science\", \"b.sc\", \"b.s\", \"bsc\", \"b.sc.\", \"b.s.\", \"honours bachelor of science\", \"bachelors of science\"],\n    \"ba\": [\"bachelor of arts\", \"b.a\", \"ba\", \"b.a.\", \"bachelors of arts\"],\n    \"bcom\": [\"bachelor of commerce\", \"b.com\", \"bcom\"],\n    \"be\": [\"bachelor of engineering\", \"b.e\", \"b.e.\", \"b.eng\", \"b.engg\", \"bachelor of engineering (b.e\"],\n    \"btech\": [\"bachelor of technology\", \"b.tech\", \"b.tech.\", \"btech\", \"b.tech(computers)\", \"dual degree (b.tech + m.tech)\", \"integrated b.tech & m.tech\"],\n    \"bba\": [\"bachelor of business administration\", \"b.b.a\", \"bba\", \"bba - accounting\", \"bba - finance\", \"bachelor business administration\"],\n    \"bca\": [\"bachelor of computer applications\", \"b.c.a\", \"bca\"],\n    \"mca\": [\"master of computer applications\", \"m.c.a\", \"mca\"],\n    \"bs\": [\"bs\", \"b.s\", \"b.s.\", \"b.s in\", \"bachelor's degree in science\", \"bachelor's in science\"],\n    \"ms\": [\"ms\", \"m.s\", \"m.s.\", \"master in computer science\", \"masters of science in information technology\"],\n    \"aa\": [\"associate of arts\", \"a.a\", \"aa\"],\n    \"aas\": [\"associate of applied science\", \"a.a.s\", \"aas\"],\n    \"as\": [\"associate of science\", \"a.s\", \"as\", \"associate of science degree\"],\n    \"associate\": [\"associate's degree\", \"associate degree\", \"associates degree\", \"associates\", \"associate\"],\n    \"diploma\": [\"technical diploma\", \"associate diploma\", \"polytechnic diploma\", \"diploma\", \"general diploma\", \"pg diploma\", \"master's diploma\"],\n    \"high school\": [\"high school diploma\", \"ged\", \"grade 12\", \"xii\", \"x\", \"kcse\"],\n    \"certificate\": [\"certificate of completion\", \"graduate certificate\", \"business certification\", \"epa certification\", \"aws brazing certification\", \"skills\", \"course\", \"certification\", \"minor\", \"training\", \"coaching\"],\n    \"others\": [\"n/a\", \"select one\", \"attending\", \"testing computer software\", \"general courses\"],\n\n    # Education levels that are more common in the Sri Lankan context\n    \"al\": [\"advanced level\", \"a/l\", \"a.l\", \"gce a/l\", \"gce advanced level\", \"gce (a/l)\", \"gce(al)\", \"gce-a/l\"],\n    \"ol\": [\"ordinary level\", \"o/l\", \"o.l\", \"gce o/l\", \"gce ordinary level\", \"gce (o/l)\", \"gce(ol)\", \"gce-o/l\"],\n    \"nvq\": [\"nvq\", \"nvq level 3\", \"nvq level 4\", \"nvq level 5\", \"nvq level 6\", \"national vocational qualification\", \"nvq diploma\"],\n    \"hnd\": [\"hnd\", \"higher national diploma\", \"hnd in\", \"higher national diploma in\"],\n    \"cima\": [\"cima\", \"chartered institute of management accountants\", \"cima qualification\"],\n    \"acca\": [\"acca\", \"association of chartered certified accountants\"],\n    \"ca\": [\"chartered accountant\", \"institute of chartered accountants of sri lanka\", \"ica\", \"ca sri lanka\"],\n    \"slim\": [\"slim\", \"slim diploma\", \"sri lanka institute of marketing\", \"slim pgd\"],\n    \"nibt\": [\"nibt\", \"national institute of business & technology\", \"nibt diploma\"],\n    \"bit\": [\"bit\", \"bachelor of information technology\", \"bit degree\", \"bit (colombo university)\"]\n\n}\n\n# Ranking the levels (higher number = higher qualification)\n# EDUCATION_RANKS = {\nEDUCATION_RANKS = {\n    \"others\": 0,\n    \n    \"high school\": 1,\n    \"certificate\": 1,\n    \"ol\": 1,\n    \n    \"al\": 2,\n    \n    \"diploma\": 3,\n    \"associate\": 3,\n    \"nvq\": 3,\n    \"hnd\": 3,\n    \"aa\": 3,\n    \"aas\": 3,\n    \"as\": 3,\n    \"slim\": 3,  \n    \"nibt\": 3,   \n    \n    \"bsc\": 4,\n    \"bs\": 4,\n    \"ba\": 4,\n    \"be\": 4,\n    \"btech\": 4,\n    \"bit\": 4,    \n    \"cima\": 4,   \n    \"acca\": 4,      \n    \"bcom\": 4,\n    \"bba\": 4,\n    \"bca\": 4,\n    \n    \"msc\": 5,\n    \"ms\": 5,\n    \"ma\": 5,\n    \"me\": 5,\n    \"mtech\": 5,\n    \"mcom\": 5,\n    \"mba\": 5,\n    \"mca\": 5,\n    \"ca\": 5,\n    \n    \"phd\": 6\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Flattenning the aliases for easy reverse lookup\nFLATTENED_EDU_ALIASES = {\n    synonym: canonical\n    for canonical, synonyms in EDUCATION_ALIASES.items()\n    for synonym in synonyms\n}\n\ndef encode_ed_req(text):\n    if not isinstance(text, str) or not text.strip():\n        return EDUCATION_RANKS[\"others\"]\n\n    best_rank = EDUCATION_RANKS[\"others\"]\n\n    parts = re.split(r'[,\\n/•;]', text.lower())\n\n    for part in parts:\n        part_clean = re.sub(r'[^\\w\\s]', '', part.strip())  # remove punctuation\n\n        # Match from aliases\n        for synonym, canonical in FLATTENED_EDU_ALIASES.items():\n            if synonym in part_clean:\n                rank = EDUCATION_RANKS.get(canonical, 0)\n                best_rank = max(best_rank, rank)\n\n        # Fallback direct canonical match\n        for canonical, rank in EDUCATION_RANKS.items():\n            if canonical in part_clean:\n                best_rank = max(best_rank, rank)\n\n    return best_rank","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['ed_req_encoded'] = df['educationaL_requirements'].apply(encode_ed_req)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cleaning major_field_of_study","metadata":{}},{"cell_type":"code","source":"def clean_major_fields(df, column_name='major_field_of_studies'):\n    df_cleaned = df.copy()\n\n    abbreviations = {\n        \"cse\": \"computer science\",\n        \"cs\": \"computer science\",\n        \"it\": \"information technology\",\n        \"computer\": \"computer science\",\n        \"computers\": \"computer science\",\n        \"ai\": \"artificial intelligence\",\n        \"ml\": \"machine learning\",\n        \"ds\": \"data science\",\n        \"ece\": \"electronics engineering\",\n        \"eee\": \"electrical engineering\",\n        \"ee\": \"electrical engineering\",\n        \"electrical\": \"electrical engineering\",\n        \"electronics\": \"electronics engineering\",\n        \"me\": \"mechanical engineering\",\n        \"ce\": \"civil engineering\",\n        \"che\": \"chemical engineering\",\n        \"mechanical\": \"mechanical engineering\",\n        \"civil\": \"civil engineering\",\n        \"chemical\": \"chemical engineering\",\n        \"finance\": \"finance\",\n        \"accounting\": \"accounting\",\n        \"business\": \"business administration\",\n        \"management\": \"business administration\",\n        \"marketing\": \"marketing\",\n        \"statistics\": \"statistics\",\n        \"economics\": \"economics\",\n        \"biology\": \"biology\",\n        \"chemistry\": \"chemistry\",\n        \"physics\": \"physics\",\n        \"math\": \"maths\",\n        \"mathematics\": \"maths\"\n    }\n\n    split_pattern = re.compile(r\"[\\/,&;|\\s]+\")\n\n    empty_values = {\"n/a\", \"none\", \"na\", \"null\", \"\", \"nan\", \"n, a\", \"n,a\", \"n\", \"a\"}\n\n    def process_value(value):\n        if pd.isna(value) or value is None:\n            return []\n        \n        value_str = str(value).lower().strip()\n\n        if value_str in empty_values:\n            return []\n\n        value_str = value_str.strip(\"[]\\\"'\")\n\n        items = [item.strip() for item in split_pattern.split(value_str) if item.strip()]\n\n        cleaned_items = []\n        for item in items:\n            if item in empty_values:\n                continue\n            cleaned_item = abbreviations.get(item, item)\n            if cleaned_item:\n                cleaned_items.append(cleaned_item)\n\n        seen = set()\n        unique_items = [x for x in cleaned_items if not (x in seen or seen.add(x))]\n\n        return unique_items if unique_items else []\n\n    df_cleaned[column_name] = df_cleaned[column_name].apply(process_value)\n    \n    return df_cleaned","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned = clean_major_fields(df, column_name='major_field_of_studies')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cleaning experience_requirements","metadata":{}},{"cell_type":"code","source":"def clean_experience_min_only(df, column_name='experience', default_value=0):\n    \"\"\"\n    Cleans experience column to extract the minimum number of years mentioned.\n    Examples:\n        'At least 3 years' → 3\n        '3 to 5 years' → 3\n        '1 to 2 years' → 1\n        NaN or invalid → default_value (e.g., 0)\n\n    Args:\n        df (pd.DataFrame): Input DataFrame\n        column_name (str): The column name to clean\n        default_value (int): Value to assign to missing/invalid entries\n\n    Returns:\n        pd.DataFrame: DataFrame with cleaned experience column\n    \"\"\"\n    def extract_min_years(value):\n        if pd.isna(value):\n            return default_value\n        # Find all numbers in the string\n        numbers = re.findall(r'\\d+', str(value))\n        if numbers:\n            return int(numbers[0])  # take the minimum\n        return default_value\n\n    df_cleaned = df.copy()\n    df_cleaned[column_name] = df_cleaned[column_name].apply(extract_min_years)\n    return df_cleaned","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_cleaned = clean_experience_min_only(df_cleaned, column_name='experiencere_requirement')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Job Experience","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef remove_na_and_none_from_list(col):\n    def clean(entry):\n        try:\n            # if already a list, skip parsing\n            if isinstance(entry, list):\n                items = entry\n            else:\n                items = ast.literal_eval(entry)\n            return [i for i in items if str(i).strip().upper() not in ['N/A', 'NONE'] and i is not None]\n        except:\n            return entry  # return original if parsing fails\n    return col.apply(clean)\n\ndf['start_dates'] = remove_na_and_none_from_list(df['start_dates'])\ndf['end_dates'] = remove_na_and_none_from_list(df['end_dates'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef replace_seasons_with_months(col):\n    # Mapping of season to month\n    season_to_month = {\n        'spring': '03',\n        'summer': '06',\n        'fall': '09',\n        'autumn': '09',\n        'winter': '12',\n    }\n\n    def replace_season(entry):\n        try:\n            items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n            updated_items = []\n            for item in items:\n                if item is None:\n                    updated_items.append(item)\n                    continue\n                # Match season followed by year, e.g., \"Summer 2013\"\n                match = re.match(r'(?i)\\b(spring|summer|fall|autumn|winter)\\b\\s+(\\d{4})', str(item).strip())\n                if match:\n                    season = match.group(1).lower()\n                    year = match.group(2)\n                    month = season_to_month.get(season)\n                    updated_items.append(f\"{month}/{year}\")\n                else:\n                    updated_items.append(item)\n            return updated_items\n        except:\n            return entry  # keep original if parsing fails\n\n    return col.apply(replace_season)\n\ndf['start_dates'] = replace_seasons_with_months(df['start_dates'])\ndf['end_dates'] = replace_seasons_with_months(df['end_dates'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datetime import datetime\nimport ast\n\ndef replace_current_terms_with_today(col):\n    today_str = datetime.today().strftime('%b %d %Y')  # Example: 'Apr 22 2025'\n    keywords = {'till date', 'current', 'ongoing', 'present', '∞'}\n\n    def clean(entry):\n        try:\n            items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n            return [\n                today_str if isinstance(i, str) and i.strip().lower() in keywords else i\n                for i in items\n            ]\n        except:\n            return entry  # return as-is if parsing fails\n\n    return col.apply(clean)\n\n# Apply it\ndf['start_dates'] = replace_current_terms_with_today(df['start_dates'])\ndf['end_dates'] = replace_current_terms_with_today(df['end_dates'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"filter and display rows where either start_dates or end_dates columns contains any item with the substring\"20XX\"","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef contains_20xx(entry):\n    try:\n        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n        return any(isinstance(i, str) and '20xx' in i.lower() for i in items)\n    except:\n        return False\n\nmask = df['start_dates'].apply(contains_20xx) | df['end_dates'].apply(contains_20xx)\ndf_with_20xx = df.loc[mask, ['start_dates', 'end_dates']]\n\nprint(df_with_20xx)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import ast\n\ndef replace_array_with_unknown(entry):\n    try:\n        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n        if any(isinstance(i, str) and '20xx' in i.lower() for i in items):\n            return 'unknown'  # Replace entire array with the string 'unknown'\n        return items\n    except:\n        return entry\n\ndf['start_dates'] = df['start_dates'].apply(replace_array_with_unknown)\ndf['end_dates'] = df['end_dates'].apply(replace_array_with_unknown)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"replace each record in start_dates and end_dates with 'unknown' if either one of them contains an empty array.","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef replace_empty_array_with_unknown(row):\n    try:\n        # Parse the entries if they are string representations of lists\n        start = ast.literal_eval(row['start_dates']) if isinstance(row['start_dates'], str) else row['start_dates']\n        end = ast.literal_eval(row['end_dates']) if isinstance(row['end_dates'], str) else row['end_dates']\n        \n        # Check if either start or end is an empty list\n        if isinstance(start, list) and len(start) == 0 or isinstance(end, list) and len(end) == 0:\n            return pd.Series({'start_dates': 'unknown', 'end_dates': 'unknown'})\n        else:\n            return pd.Series({'start_dates': row['start_dates'], 'end_dates': row['end_dates']})\n    except:\n        # In case of any parsing error, return the original values\n        return pd.Series({'start_dates': row['start_dates'], 'end_dates': row['end_dates']})\n\n# Apply the function to each row\ndf[['start_dates', 'end_dates']] = df.apply(replace_empty_array_with_unknown, axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"converting all dates in string format to YYYY-MM","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom dateutil import parser\nimport ast\n\ndef standardize_date_array(entry):\n    if isinstance(entry, str) and entry == 'unknown':\n        return entry\n    if isinstance(entry, float) and pd.isna(entry):\n        return entry\n\n    try:\n        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n        if not isinstance(items, list):  # guard clause\n            return entry\n\n        cleaned = []\n        for item in items:\n            if isinstance(item, str):\n                try:\n                    parsed = parser.parse(item, fuzzy=True)\n                    cleaned.append(parsed.strftime('%Y-%m'))\n                except:\n                    cleaned.append(item)\n            else:\n                cleaned.append(item)\n        return cleaned\n    except:\n        return entry\n    \ndf['start_dates'] = df['start_dates'].apply(standardize_date_array)\ndf['end_dates'] = df['end_dates'].apply(standardize_date_array)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"check if there are arrays with unequal length","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef count_unequal_length_date_arrays(df):\n    count = 0\n    for start, end in zip(df['start_dates'], df['end_dates']):\n        if isinstance(start, list) and isinstance(end, list):\n            if len(start) != len(end):\n                count += 1\n    return count\n\nunequal_length_count = count_unequal_length_date_arrays(df)\nprint(\"Total records with unequal-length date arrays:\", unequal_length_count)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"replace the entries having unequal array length with string 'unknown'.","metadata":{}},{"cell_type":"code","source":"def replace_unequal_length_records(df):\n    for idx, (start, end) in enumerate(zip(df['start_dates'], df['end_dates'])):\n        if isinstance(start, list) and isinstance(end, list):\n            if len(start) != len(end):\n                df.at[idx, 'start_dates'] = 'unknown'\n                df.at[idx, 'end_dates'] = 'unknown'\n    return df\n\n# Apply the function to your dataframe\ndf = replace_unequal_length_records(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"sorting the dates arrays in accending order in both columns","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\n\ndef sort_dates_in_array(entry):\n    try:\n        # Convert string dates to datetime objects for sorting\n        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n        # Sort the items based on datetime conversion\n        sorted_items = sorted(items, key=lambda x: datetime.strptime(x, '%b %Y') if ' ' in x else datetime.strptime(x, '%m/%Y') if '/' in x else datetime.strptime(x, '%Y-%m'))\n        return sorted_items\n    except:\n        return entry  # If any error occurs, return the original entry\n\n# Apply the sorting function to both start_dates and end_dates\ndf['start_dates'] = df['start_dates'].apply(sort_dates_in_array)\ndf['end_dates'] = df['end_dates'].apply(sort_dates_in_array)\nfrom datetime import datetime\n\ndef sort_dates_in_array(entry):\n    try:\n        # Convert string dates to datetime objects for sorting\n        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n        # Sort the items based on datetime conversion\n        sorted_items = sorted(items, key=lambda x: datetime.strptime(x, '%b %Y') if ' ' in x else datetime.strptime(x, '%m/%Y') if '/' in x else datetime.strptime(x, '%Y-%m'))\n        return sorted_items\n    except:\n        return entry  # If any error occurs, return the original entry\n\n# Apply the sorting function to both start_dates and end_dates\ndf['start_dates'] = df['start_dates'].apply(sort_dates_in_array)\ndf['end_dates'] = df['end_dates'].apply(sort_dates_in_array)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def calculate_experience(start_dates, end_dates):\n    # Check for 'unknown' in strings\n    if isinstance(start_dates, str) and start_dates.lower() == 'unknown':\n        return 'unknown'\n    if isinstance(end_dates, str) and end_dates.lower() == 'unknown':\n        return 'unknown'\n\n    # Check for 'unknown' inside lists\n    if isinstance(start_dates, list) and any(str(d).lower() == 'unknown' for d in start_dates):\n        return 'unknown'\n    if isinstance(end_dates, list) and any(str(d).lower() == 'unknown' for d in end_dates):\n        return 'unknown'\n\n    # Check for NaNs safely\n    if isinstance(start_dates, list):\n        if any(pd.isna(d) for d in start_dates):\n            return np.nan\n    elif pd.isna(start_dates):\n        return np.nan\n\n    if isinstance(end_dates, list):\n        if any(pd.isna(d) for d in end_dates):\n            return np.nan\n    elif pd.isna(end_dates):\n        return np.nan\n\n    # Calculate total years of experience\n    total_years = 0\n    for start, end in zip(start_dates, end_dates):\n        try:\n            start_dt = datetime.strptime(str(start).strip(), '%Y-%m')\n            end_dt = datetime.strptime(str(end).strip(), '%Y-%m')\n            total_years += (end_dt - start_dt).days / 365.25\n        except Exception:\n            return np.nan  # Invalid date format\n\n    return round(total_years, 2) if total_years != 0 else np.nan\n\ndf['experience_years'] = df.apply(\n    lambda row: calculate_experience(row['start_dates'], row['end_dates']),\n    axis=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count how many 'unknown' strings are in the experience_years column\nunknown_experience_count = (df['experience_years']=='unknown').sum()\n\nprint(\"Total 'unknown' in experience_years:\", unknown_experience_count)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.drop(['start_dates', 'end_dates'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"total 'unknown' s are 788 and total 'nan's 112.","metadata":{}},{"cell_type":"markdown","source":"# Cleaning Skills","metadata":{}},{"cell_type":"code","source":"import ast\nimport re\n\ndef clean_and_merge_skills(df, col1, col2, col3, new_col='merged_skills'):\n    # Helper: Parse and clean a single cell\n    def parse_and_clean(cell):\n        try:\n            parsed = ast.literal_eval(cell)\n        except Exception:\n            return []\n\n        def flatten(x):\n            if isinstance(x, list):\n                return [item for sub in x for item in flatten(sub)]\n            return [x]\n\n        flat = flatten(parsed)\n        cleaned = [s.strip().lower() for s in flat if isinstance(s, str)]\n        return cleaned\n\n    # Helper: Check if the list only contains generic skill patterns\n    def is_generic_skills_list(skill_list):\n        pattern = re.compile(r'^skill\\s*\\d+$')\n        return all(pattern.match(s) for s in skill_list) and len(skill_list) > 0\n\n    # Clean both columns\n    cleaned_col1 = df[col1].apply(parse_and_clean)\n    cleaned_col2 = df[col2].apply(parse_and_clean)\n    cleaned_col3 = df[col3].apply(parse_and_clean)\n\n    # Merge and deduplicate\n    df[new_col] = [\n        list(dict.fromkeys(c1 + c2 + c3)) for c1, c2, c3 in zip(cleaned_col1, cleaned_col2, cleaned_col3)\n    ]\n\n    # Remove generic skill lists\n    df[new_col] = df[new_col].apply(lambda skills: [] if is_generic_skills_list(skills) else skills)\n\n    # Drop original columns\n    df.drop(columns=[col1, col2, col3], inplace=True)\n\n    return df\n\nclean_and_merge_skills(df, 'skills', 'related_skils_in_job', 'certification_skills', new_col='merged_skills')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}