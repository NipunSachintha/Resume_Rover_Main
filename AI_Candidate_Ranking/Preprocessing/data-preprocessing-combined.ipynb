{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-22T05:14:43.330804Z",
     "iopub.status.busy": "2025-04-22T05:14:43.330545Z",
     "iopub.status.idle": "2025-04-22T05:14:43.711555Z",
     "shell.execute_reply": "2025-04-22T05:14:43.710790Z",
     "shell.execute_reply.started": "2025-04-22T05:14:43.330776Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/resume-dataset-for-resume-ranking-group-10/resume_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the degree_names into desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Second method (using aliases)\n",
    "\n",
    "import re\n",
    "\n",
    "# Mapping canonical degree to various common forms\n",
    "# EDUCATION_ALIASES = {\n",
    "#     \"phd\": [\"doctor of philosophy\", \"ph.d\", \"doctorate\"],\n",
    "#     \"mba\": [\"master of business administration\", \"mba executive\"],\n",
    "#     \"bsc\": [\"bachelor of science\", \"b.sc\", \"b.s\"],\n",
    "#     \"msc\": [\"master of science\", \"m.sc\", \"m.s\"],\n",
    "#     \"ba\": [\"bachelor of arts\"],\n",
    "#     \"ma\": [\"master of arts\"],\n",
    "#     \"bcom\": [\"bachelor of commerce\", \"b.com\"],\n",
    "#     \"mcom\": [\"master of commerce\", \"m.com\"],\n",
    "#     \"be\": [\"bachelor of engineering\", \"b.e\", \"b.eng\"],\n",
    "#     \"me\": [\"master of engineering\", \"m.e\", \"m.eng\"],\n",
    "#     \"bba\": [\"bachelor of business administration\"],\n",
    "#     \"mtech\": [\"master of technology\"],\n",
    "#     \"btech\": [\"bachelor of technology\"],\n",
    "#     \"diploma\": [\"technical diploma\", \"associate diploma\", \"polytechnic diploma\"],\n",
    "#     \"high school\": [\"high school diploma\", \"gce o-level\", \"ged\", \"gce a-level\"],\n",
    "# }\n",
    "EDUCATION_ALIASES = {\n",
    "    \"phd\": [\"doctor of philosophy\", \"ph.d\", \"ph.d.\", \"phd\", \"doctorate\", \"ph.d. in\", \"phd candidate\"],\n",
    "    \"mba\": [\"master of business administration\", \"mba executive\", \"executive mba\", \"mba\", \"masters of business administration\"],\n",
    "    \"msc\": [\"master of science\", \"m.sc\", \"m.s\", \"masters of science\", \"msc\", \"masters in science\", \"m.sc.\"],\n",
    "    \"ma\": [\"master of arts\", \"m.a\", \"m.a.\", \"masters of arts\"],\n",
    "    \"mcom\": [\"master of commerce\", \"m.com\", \"mcom\"],\n",
    "    \"me\": [\"master of engineering\", \"m.e\", \"m.eng\", \"m.e.\", \"m.engg\"],\n",
    "    \"mtech\": [\"master of technology\", \"m.tech\", \"mtech\", \"mtech integrated\"],\n",
    "    \"bsc\": [\"bachelor of science\", \"b.sc\", \"b.s\", \"bsc\", \"b.sc.\", \"b.s.\", \"honours bachelor of science\", \"bachelors of science\"],\n",
    "    \"ba\": [\"bachelor of arts\", \"b.a\", \"ba\", \"b.a.\", \"bachelors of arts\"],\n",
    "    \"bcom\": [\"bachelor of commerce\", \"b.com\", \"bcom\"],\n",
    "    \"be\": [\"bachelor of engineering\", \"b.e\", \"b.e.\", \"b.eng\", \"b.engg\", \"bachelor of engineering (b.e\"],\n",
    "    \"btech\": [\"bachelor of technology\", \"b.tech\", \"b.tech.\", \"btech\", \"b.tech(computers)\", \"dual degree (b.tech + m.tech)\", \"integrated b.tech & m.tech\"],\n",
    "    \"bba\": [\"bachelor of business administration\", \"b.b.a\", \"bba\", \"bba - accounting\", \"bba - finance\", \"bachelor business administration\"],\n",
    "    \"bca\": [\"bachelor of computer applications\", \"b.c.a\", \"bca\"],\n",
    "    \"mca\": [\"master of computer applications\", \"m.c.a\", \"mca\"],\n",
    "    \"bs\": [\"bs\", \"b.s\", \"b.s.\", \"b.s in\", \"bachelor's degree in science\", \"bachelor's in science\"],\n",
    "    \"ms\": [\"ms\", \"m.s\", \"m.s.\", \"master in computer science\", \"masters of science in information technology\"],\n",
    "    \"aa\": [\"associate of arts\", \"a.a\", \"aa\"],\n",
    "    \"aas\": [\"associate of applied science\", \"a.a.s\", \"aas\"],\n",
    "    \"as\": [\"associate of science\", \"a.s\", \"as\", \"associate of science degree\"],\n",
    "    \"associate\": [\"associate's degree\", \"associate degree\", \"associates degree\", \"associates\", \"associate\"],\n",
    "    \"diploma\": [\"technical diploma\", \"associate diploma\", \"polytechnic diploma\", \"diploma\", \"general diploma\", \"pg diploma\", \"master's diploma\"],\n",
    "    \"high school\": [\"high school diploma\", \"ged\", \"grade 12\", \"xii\", \"x\", \"kcse\"],\n",
    "    \"certificate\": [\"certificate of completion\", \"graduate certificate\", \"business certification\", \"epa certification\", \"aws brazing certification\", \"skills\", \"course\", \"certification\", \"minor\", \"training\", \"coaching\"],\n",
    "    \"others\": [\"n/a\", \"select one\", \"attending\", \"testing computer software\", \"general courses\"],\n",
    "\n",
    "    # Education levels that are more common in the Sri Lankan context\n",
    "    \"al\": [\"advanced level\", \"a/l\", \"a.l\", \"gce a/l\", \"gce advanced level\", \"gce (a/l)\", \"gce(al)\", \"gce-a/l\"],\n",
    "    \"ol\": [\"ordinary level\", \"o/l\", \"o.l\", \"gce o/l\", \"gce ordinary level\", \"gce (o/l)\", \"gce(ol)\", \"gce-o/l\"],\n",
    "    \"nvq\": [\"nvq\", \"nvq level 3\", \"nvq level 4\", \"nvq level 5\", \"nvq level 6\", \"national vocational qualification\", \"nvq diploma\"],\n",
    "    \"hnd\": [\"hnd\", \"higher national diploma\", \"hnd in\", \"higher national diploma in\"],\n",
    "    \"cima\": [\"cima\", \"chartered institute of management accountants\", \"cima qualification\"],\n",
    "    \"acca\": [\"acca\", \"association of chartered certified accountants\"],\n",
    "    \"ca\": [\"chartered accountant\", \"institute of chartered accountants of sri lanka\", \"ica\", \"ca sri lanka\"],\n",
    "    \"slim\": [\"slim\", \"slim diploma\", \"sri lanka institute of marketing\", \"slim pgd\"],\n",
    "    \"nibt\": [\"nibt\", \"national institute of business & technology\", \"nibt diploma\"],\n",
    "    \"bit\": [\"bit\", \"bachelor of information technology\", \"bit degree\", \"bit (colombo university)\"]\n",
    "\n",
    "}\n",
    "\n",
    "# Ranking the levels (higher number = higher qualification)\n",
    "# EDUCATION_RANKS = {\n",
    "#     \"high school\": 0,\n",
    "#     \"diploma\": 2,\n",
    "#     \"bsc\": 3,\n",
    "#     \"ba\": 3,\n",
    "#     \"be\": 3,\n",
    "#     \"bcom\": 3,\n",
    "#     \"bba\": 3,\n",
    "#     \"btech\": 3,\n",
    "#     \"msc\": 4,\n",
    "#     \"ma\": 4,\n",
    "#     \"mba\": 4,\n",
    "#     \"mtech\": 4,\n",
    "#     \"me\": 4,\n",
    "#     \"phd\": 5\n",
    "# }\n",
    "EDUCATION_RANKS = {\n",
    "    \"others\": 0,\n",
    "    \n",
    "    \"high school\": 1,\n",
    "    \"certificate\": 1,\n",
    "    \"ol\": 1,\n",
    "    \n",
    "    \"al\": 2,\n",
    "    \n",
    "    \"diploma\": 3,\n",
    "    \"associate\": 3,\n",
    "    \"nvq\": 3,\n",
    "    \"hnd\": 3,\n",
    "    \"aa\": 3,\n",
    "    \"aas\": 3,\n",
    "    \"as\": 3,\n",
    "    \"slim\": 3,  \n",
    "    \"nibt\": 3,   \n",
    "    \n",
    "    \"bsc\": 4,\n",
    "    \"bs\": 4,\n",
    "    \"ba\": 4,\n",
    "    \"be\": 4,\n",
    "    \"btech\": 4,\n",
    "    \"bit\": 4,    \n",
    "    \"cima\": 4,   \n",
    "    \"acca\": 4,      \n",
    "    \"bcom\": 4,\n",
    "    \"bba\": 4,\n",
    "    \"bca\": 4,\n",
    "    \n",
    "    \"msc\": 5,\n",
    "    \"ms\": 5,\n",
    "    \"ma\": 5,\n",
    "    \"me\": 5,\n",
    "    \"mtech\": 5,\n",
    "    \"mcom\": 5,\n",
    "    \"mba\": 5,\n",
    "    \"mca\": 5,\n",
    "    \"ca\": 5,\n",
    "    \n",
    "    \"phd\": 6\n",
    "}\n",
    "\n",
    "# Flattenning the aliases for easy reverse lookup\n",
    "FLATTENED_ALIASES = {}\n",
    "for canonical, synonyms in EDUCATION_ALIASES.items():\n",
    "    for synonym in synonyms:\n",
    "        FLATTENED_ALIASES[synonym.lower()] = canonical\n",
    "\n",
    "\n",
    "def get_highest_education(degree_entries):\n",
    "    if not isinstance(degree_entries, list):\n",
    "        degree_entries = [degree_entries]\n",
    "\n",
    "    best_match = (\"unknown\", -1)\n",
    "\n",
    "    for entry in degree_entries:\n",
    "        if not isinstance(entry, str):\n",
    "            continue\n",
    "\n",
    "        # Clean and normalize text\n",
    "        text = re.sub(r'[^\\w\\s]', '', entry.lower())\n",
    "\n",
    "        # Try matching from aliases\n",
    "        for synonym, canonical in FLATTENED_ALIASES.items():\n",
    "            if synonym in text:\n",
    "                rank = EDUCATION_RANKS.get(canonical, -1)\n",
    "                if rank > best_match[1]:\n",
    "                    best_match = (canonical, rank)\n",
    "\n",
    "        # Fallback to direct canonical keyword matching\n",
    "        for canonical, rank in EDUCATION_RANKS.items():\n",
    "            if canonical in text:\n",
    "                if rank > best_match[1]:\n",
    "                    best_match = (canonical, rank)\n",
    "\n",
    "    return best_match[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['highest_degree'] = df['degree_names'].apply(get_highest_education)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Educational Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Mapping canonical degree to various common forms\n",
    "EDUCATION_ALIASES = {\n",
    "    \"phd\": [\"doctor of philosophy\", \"ph.d\", \"ph.d.\", \"phd\", \"doctorate\", \"ph.d. in\", \"phd candidate\"],\n",
    "    \"mba\": [\"master of business administration\", \"mba executive\", \"executive mba\", \"mba\", \"masters of business administration\"],\n",
    "    \"msc\": [\"master of science\", \"m.sc\", \"m.s\", \"masters of science\", \"msc\", \"masters in science\", \"m.sc.\"],\n",
    "    \"ma\": [\"master of arts\", \"m.a\", \"m.a.\", \"masters of arts\"],\n",
    "    \"mcom\": [\"master of commerce\", \"m.com\", \"mcom\"],\n",
    "    \"me\": [\"master of engineering\", \"m.e\", \"m.eng\", \"m.e.\", \"m.engg\"],\n",
    "    \"mtech\": [\"master of technology\", \"m.tech\", \"mtech\", \"mtech integrated\"],\n",
    "    \"bsc\": [\"bachelor of science\", \"b.sc\", \"b.s\", \"bsc\", \"b.sc.\", \"b.s.\", \"honours bachelor of science\", \"bachelors of science\"],\n",
    "    \"ba\": [\"bachelor of arts\", \"b.a\", \"ba\", \"b.a.\", \"bachelors of arts\"],\n",
    "    \"bcom\": [\"bachelor of commerce\", \"b.com\", \"bcom\"],\n",
    "    \"be\": [\"bachelor of engineering\", \"b.e\", \"b.e.\", \"b.eng\", \"b.engg\", \"bachelor of engineering (b.e\"],\n",
    "    \"btech\": [\"bachelor of technology\", \"b.tech\", \"b.tech.\", \"btech\", \"b.tech(computers)\", \"dual degree (b.tech + m.tech)\", \"integrated b.tech & m.tech\"],\n",
    "    \"bba\": [\"bachelor of business administration\", \"b.b.a\", \"bba\", \"bba - accounting\", \"bba - finance\", \"bachelor business administration\"],\n",
    "    \"bca\": [\"bachelor of computer applications\", \"b.c.a\", \"bca\"],\n",
    "    \"mca\": [\"master of computer applications\", \"m.c.a\", \"mca\"],\n",
    "    \"bs\": [\"bs\", \"b.s\", \"b.s.\", \"b.s in\", \"bachelor's degree in science\", \"bachelor's in science\"],\n",
    "    \"ms\": [\"ms\", \"m.s\", \"m.s.\", \"master in computer science\", \"masters of science in information technology\"],\n",
    "    \"aa\": [\"associate of arts\", \"a.a\", \"aa\"],\n",
    "    \"aas\": [\"associate of applied science\", \"a.a.s\", \"aas\"],\n",
    "    \"as\": [\"associate of science\", \"a.s\", \"as\", \"associate of science degree\"],\n",
    "    \"associate\": [\"associate's degree\", \"associate degree\", \"associates degree\", \"associates\", \"associate\"],\n",
    "    \"diploma\": [\"technical diploma\", \"associate diploma\", \"polytechnic diploma\", \"diploma\", \"general diploma\", \"pg diploma\", \"master's diploma\"],\n",
    "    \"high school\": [\"high school diploma\", \"ged\", \"grade 12\", \"xii\", \"x\", \"kcse\"],\n",
    "    \"certificate\": [\"certificate of completion\", \"graduate certificate\", \"business certification\", \"epa certification\", \"aws brazing certification\", \"skills\", \"course\", \"certification\", \"minor\", \"training\", \"coaching\"],\n",
    "    \"others\": [\"n/a\", \"select one\", \"attending\", \"testing computer software\", \"general courses\"],\n",
    "\n",
    "    # Education levels that are more common in the Sri Lankan context\n",
    "    \"al\": [\"advanced level\", \"a/l\", \"a.l\", \"gce a/l\", \"gce advanced level\", \"gce (a/l)\", \"gce(al)\", \"gce-a/l\"],\n",
    "    \"ol\": [\"ordinary level\", \"o/l\", \"o.l\", \"gce o/l\", \"gce ordinary level\", \"gce (o/l)\", \"gce(ol)\", \"gce-o/l\"],\n",
    "    \"nvq\": [\"nvq\", \"nvq level 3\", \"nvq level 4\", \"nvq level 5\", \"nvq level 6\", \"national vocational qualification\", \"nvq diploma\"],\n",
    "    \"hnd\": [\"hnd\", \"higher national diploma\", \"hnd in\", \"higher national diploma in\"],\n",
    "    \"cima\": [\"cima\", \"chartered institute of management accountants\", \"cima qualification\"],\n",
    "    \"acca\": [\"acca\", \"association of chartered certified accountants\"],\n",
    "    \"ca\": [\"chartered accountant\", \"institute of chartered accountants of sri lanka\", \"ica\", \"ca sri lanka\"],\n",
    "    \"slim\": [\"slim\", \"slim diploma\", \"sri lanka institute of marketing\", \"slim pgd\"],\n",
    "    \"nibt\": [\"nibt\", \"national institute of business & technology\", \"nibt diploma\"],\n",
    "    \"bit\": [\"bit\", \"bachelor of information technology\", \"bit degree\", \"bit (colombo university)\"]\n",
    "\n",
    "}\n",
    "\n",
    "# Ranking the levels (higher number = higher qualification)\n",
    "# EDUCATION_RANKS = {\n",
    "EDUCATION_RANKS = {\n",
    "    \"others\": 0,\n",
    "    \n",
    "    \"high school\": 1,\n",
    "    \"certificate\": 1,\n",
    "    \"ol\": 1,\n",
    "    \n",
    "    \"al\": 2,\n",
    "    \n",
    "    \"diploma\": 3,\n",
    "    \"associate\": 3,\n",
    "    \"nvq\": 3,\n",
    "    \"hnd\": 3,\n",
    "    \"aa\": 3,\n",
    "    \"aas\": 3,\n",
    "    \"as\": 3,\n",
    "    \"slim\": 3,  \n",
    "    \"nibt\": 3,   \n",
    "    \n",
    "    \"bsc\": 4,\n",
    "    \"bs\": 4,\n",
    "    \"ba\": 4,\n",
    "    \"be\": 4,\n",
    "    \"btech\": 4,\n",
    "    \"bit\": 4,    \n",
    "    \"cima\": 4,   \n",
    "    \"acca\": 4,      \n",
    "    \"bcom\": 4,\n",
    "    \"bba\": 4,\n",
    "    \"bca\": 4,\n",
    "    \n",
    "    \"msc\": 5,\n",
    "    \"ms\": 5,\n",
    "    \"ma\": 5,\n",
    "    \"me\": 5,\n",
    "    \"mtech\": 5,\n",
    "    \"mcom\": 5,\n",
    "    \"mba\": 5,\n",
    "    \"mca\": 5,\n",
    "    \"ca\": 5,\n",
    "    \n",
    "    \"phd\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Flattenning the aliases for easy reverse lookup\n",
    "FLATTENED_EDU_ALIASES = {\n",
    "    synonym: canonical\n",
    "    for canonical, synonyms in EDUCATION_ALIASES.items()\n",
    "    for synonym in synonyms\n",
    "}\n",
    "\n",
    "def encode_ed_req(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return EDUCATION_RANKS[\"others\"]\n",
    "\n",
    "    best_rank = EDUCATION_RANKS[\"others\"]\n",
    "\n",
    "    parts = re.split(r'[,\\n/•;]', text.lower())\n",
    "\n",
    "    for part in parts:\n",
    "        part_clean = re.sub(r'[^\\w\\s]', '', part.strip())  # remove punctuation\n",
    "\n",
    "        # Match from aliases\n",
    "        for synonym, canonical in FLATTENED_EDU_ALIASES.items():\n",
    "            if synonym in part_clean:\n",
    "                rank = EDUCATION_RANKS.get(canonical, 0)\n",
    "                best_rank = max(best_rank, rank)\n",
    "\n",
    "        # Fallback direct canonical match\n",
    "        for canonical, rank in EDUCATION_RANKS.items():\n",
    "            if canonical in part_clean:\n",
    "                best_rank = max(best_rank, rank)\n",
    "\n",
    "    return best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['ed_req_encoded'] = df['educationaL_requirements'].apply(encode_ed_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning major_field_of_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_major_fields(df, column_name='major_field_of_studies'):\n",
    "    df_cleaned = df.copy()\n",
    "\n",
    "    abbreviations = {\n",
    "        \"cse\": \"computer science\",\n",
    "        \"cs\": \"computer science\",\n",
    "        \"it\": \"information technology\",\n",
    "        \"computer\": \"computer science\",\n",
    "        \"computers\": \"computer science\",\n",
    "        \"ai\": \"artificial intelligence\",\n",
    "        \"ml\": \"machine learning\",\n",
    "        \"ds\": \"data science\",\n",
    "        \"ece\": \"electronics engineering\",\n",
    "        \"eee\": \"electrical engineering\",\n",
    "        \"ee\": \"electrical engineering\",\n",
    "        \"electrical\": \"electrical engineering\",\n",
    "        \"electronics\": \"electronics engineering\",\n",
    "        \"me\": \"mechanical engineering\",\n",
    "        \"ce\": \"civil engineering\",\n",
    "        \"che\": \"chemical engineering\",\n",
    "        \"mechanical\": \"mechanical engineering\",\n",
    "        \"civil\": \"civil engineering\",\n",
    "        \"chemical\": \"chemical engineering\",\n",
    "        \"finance\": \"finance\",\n",
    "        \"accounting\": \"accounting\",\n",
    "        \"business\": \"business administration\",\n",
    "        \"management\": \"business administration\",\n",
    "        \"marketing\": \"marketing\",\n",
    "        \"statistics\": \"statistics\",\n",
    "        \"economics\": \"economics\",\n",
    "        \"biology\": \"biology\",\n",
    "        \"chemistry\": \"chemistry\",\n",
    "        \"physics\": \"physics\",\n",
    "        \"math\": \"maths\",\n",
    "        \"mathematics\": \"maths\"\n",
    "    }\n",
    "\n",
    "    split_pattern = re.compile(r\"[\\/,&;|\\s]+\")\n",
    "\n",
    "    empty_values = {\"n/a\", \"none\", \"na\", \"null\", \"\", \"nan\", \"n, a\", \"n,a\", \"n\", \"a\"}\n",
    "\n",
    "    def process_value(value):\n",
    "        if pd.isna(value) or value is None:\n",
    "            return []\n",
    "        \n",
    "        value_str = str(value).lower().strip()\n",
    "\n",
    "        if value_str in empty_values:\n",
    "            return []\n",
    "\n",
    "        value_str = value_str.strip(\"[]\\\"'\")\n",
    "\n",
    "        items = [item.strip() for item in split_pattern.split(value_str) if item.strip()]\n",
    "\n",
    "        cleaned_items = []\n",
    "        for item in items:\n",
    "            if item in empty_values:\n",
    "                continue\n",
    "            cleaned_item = abbreviations.get(item, item)\n",
    "            if cleaned_item:\n",
    "                cleaned_items.append(cleaned_item)\n",
    "\n",
    "        seen = set()\n",
    "        unique_items = [x for x in cleaned_items if not (x in seen or seen.add(x))]\n",
    "\n",
    "        return unique_items if unique_items else []\n",
    "\n",
    "    df_cleaned[column_name] = df_cleaned[column_name].apply(process_value)\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_cleaned = clean_major_fields(df, column_name='major_field_of_studies')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning experience_requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_experience_min_only(df, column_name='experience', default_value=0):\n",
    "    \"\"\"\n",
    "    Cleans experience column to extract the minimum number of years mentioned.\n",
    "    Examples:\n",
    "        'At least 3 years' → 3\n",
    "        '3 to 5 years' → 3\n",
    "        '1 to 2 years' → 1\n",
    "        NaN or invalid → default_value (e.g., 0)\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame\n",
    "        column_name (str): The column name to clean\n",
    "        default_value (int): Value to assign to missing/invalid entries\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned experience column\n",
    "    \"\"\"\n",
    "    def extract_min_years(value):\n",
    "        if pd.isna(value):\n",
    "            return default_value\n",
    "        # Find all numbers in the string\n",
    "        numbers = re.findall(r'\\d+', str(value))\n",
    "        if numbers:\n",
    "            return int(numbers[0])  # take the minimum\n",
    "        return default_value\n",
    "\n",
    "    df_cleaned = df.copy()\n",
    "    df_cleaned[column_name] = df_cleaned[column_name].apply(extract_min_years)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_cleaned = clean_experience_min_only(df_cleaned, column_name='experiencere_requirement')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def remove_na_and_none_from_list(col):\n",
    "    def clean(entry):\n",
    "        try:\n",
    "            # if already a list, skip parsing\n",
    "            if isinstance(entry, list):\n",
    "                items = entry\n",
    "            else:\n",
    "                items = ast.literal_eval(entry)\n",
    "            return [i for i in items if str(i).strip().upper() not in ['N/A', 'NONE'] and i is not None]\n",
    "        except:\n",
    "            return entry  # return original if parsing fails\n",
    "    return col.apply(clean)\n",
    "\n",
    "df['start_dates'] = remove_na_and_none_from_list(df['start_dates'])\n",
    "df['end_dates'] = remove_na_and_none_from_list(df['end_dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_seasons_with_months(col):\n",
    "    # Mapping of season to month\n",
    "    season_to_month = {\n",
    "        'spring': '03',\n",
    "        'summer': '06',\n",
    "        'fall': '09',\n",
    "        'autumn': '09',\n",
    "        'winter': '12',\n",
    "    }\n",
    "\n",
    "    def replace_season(entry):\n",
    "        try:\n",
    "            items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n",
    "            updated_items = []\n",
    "            for item in items:\n",
    "                if item is None:\n",
    "                    updated_items.append(item)\n",
    "                    continue\n",
    "                # Match season followed by year, e.g., \"Summer 2013\"\n",
    "                match = re.match(r'(?i)\\b(spring|summer|fall|autumn|winter)\\b\\s+(\\d{4})', str(item).strip())\n",
    "                if match:\n",
    "                    season = match.group(1).lower()\n",
    "                    year = match.group(2)\n",
    "                    month = season_to_month.get(season)\n",
    "                    updated_items.append(f\"{month}/{year}\")\n",
    "                else:\n",
    "                    updated_items.append(item)\n",
    "            return updated_items\n",
    "        except:\n",
    "            return entry  # keep original if parsing fails\n",
    "\n",
    "    return col.apply(replace_season)\n",
    "\n",
    "df['start_dates'] = replace_seasons_with_months(df['start_dates'])\n",
    "df['end_dates'] = replace_seasons_with_months(df['end_dates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "def replace_current_terms_with_today(col):\n",
    "    today_str = datetime.today().strftime('%b %d %Y')  # Example: 'Apr 22 2025'\n",
    "    keywords = {'till date', 'current', 'ongoing', 'present', '∞'}\n",
    "\n",
    "    def clean(entry):\n",
    "        try:\n",
    "            items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n",
    "            return [\n",
    "                today_str if isinstance(i, str) and i.strip().lower() in keywords else i\n",
    "                for i in items\n",
    "            ]\n",
    "        except:\n",
    "            return entry  # return as-is if parsing fails\n",
    "\n",
    "    return col.apply(clean)\n",
    "\n",
    "# Apply it\n",
    "df['start_dates'] = replace_current_terms_with_today(df['start_dates'])\n",
    "df['end_dates'] = replace_current_terms_with_today(df['end_dates'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter and display rows where either start_dates or end_dates columns contains any item with the substring\"20XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def contains_20xx(entry):\n",
    "    try:\n",
    "        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n",
    "        return any(isinstance(i, str) and '20xx' in i.lower() for i in items)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "mask = df['start_dates'].apply(contains_20xx) | df['end_dates'].apply(contains_20xx)\n",
    "df_with_20xx = df.loc[mask, ['start_dates', 'end_dates']]\n",
    "\n",
    "print(df_with_20xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def replace_array_with_unknown(entry):\n",
    "    try:\n",
    "        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n",
    "        if any(isinstance(i, str) and '20xx' in i.lower() for i in items):\n",
    "            return 'unknown'  # Replace entire array with the string 'unknown'\n",
    "        return items\n",
    "    except:\n",
    "        return entry\n",
    "\n",
    "df['start_dates'] = df['start_dates'].apply(replace_array_with_unknown)\n",
    "df['end_dates'] = df['end_dates'].apply(replace_array_with_unknown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace each record in start_dates and end_dates with 'unknown' if either one of them contains an empty array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def replace_empty_array_with_unknown(row):\n",
    "    try:\n",
    "        # Parse the entries if they are string representations of lists\n",
    "        start = ast.literal_eval(row['start_dates']) if isinstance(row['start_dates'], str) else row['start_dates']\n",
    "        end = ast.literal_eval(row['end_dates']) if isinstance(row['end_dates'], str) else row['end_dates']\n",
    "        \n",
    "        # Check if either start or end is an empty list\n",
    "        if isinstance(start, list) and len(start) == 0 or isinstance(end, list) and len(end) == 0:\n",
    "            return pd.Series({'start_dates': 'unknown', 'end_dates': 'unknown'})\n",
    "        else:\n",
    "            return pd.Series({'start_dates': row['start_dates'], 'end_dates': row['end_dates']})\n",
    "    except:\n",
    "        # In case of any parsing error, return the original values\n",
    "        return pd.Series({'start_dates': row['start_dates'], 'end_dates': row['end_dates']})\n",
    "\n",
    "# Apply the function to each row\n",
    "df[['start_dates', 'end_dates']] = df.apply(replace_empty_array_with_unknown, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting all dates in string format to YYYY-MM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "import ast\n",
    "\n",
    "def standardize_date_array(entry):\n",
    "    if isinstance(entry, str) and entry == 'unknown':\n",
    "        return entry\n",
    "    if isinstance(entry, float) and pd.isna(entry):\n",
    "        return entry\n",
    "\n",
    "    try:\n",
    "        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n",
    "        if not isinstance(items, list):  # guard clause\n",
    "            return entry\n",
    "\n",
    "        cleaned = []\n",
    "        for item in items:\n",
    "            if isinstance(item, str):\n",
    "                try:\n",
    "                    parsed = parser.parse(item, fuzzy=True)\n",
    "                    cleaned.append(parsed.strftime('%Y-%m'))\n",
    "                except:\n",
    "                    cleaned.append(item)\n",
    "            else:\n",
    "                cleaned.append(item)\n",
    "        return cleaned\n",
    "    except:\n",
    "        return entry\n",
    "    \n",
    "df['start_dates'] = df['start_dates'].apply(standardize_date_array)\n",
    "df['end_dates'] = df['end_dates'].apply(standardize_date_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if there are arrays with unequal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def count_unequal_length_date_arrays(df):\n",
    "    count = 0\n",
    "    for start, end in zip(df['start_dates'], df['end_dates']):\n",
    "        if isinstance(start, list) and isinstance(end, list):\n",
    "            if len(start) != len(end):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "unequal_length_count = count_unequal_length_date_arrays(df)\n",
    "print(\"Total records with unequal-length date arrays:\", unequal_length_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace the entries having unequal array length with string 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def replace_unequal_length_records(df):\n",
    "    for idx, (start, end) in enumerate(zip(df['start_dates'], df['end_dates'])):\n",
    "        if isinstance(start, list) and isinstance(end, list):\n",
    "            if len(start) != len(end):\n",
    "                df.at[idx, 'start_dates'] = 'unknown'\n",
    "                df.at[idx, 'end_dates'] = 'unknown'\n",
    "    return df\n",
    "\n",
    "# Apply the function to your dataframe\n",
    "df = replace_unequal_length_records(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorting the dates arrays in accending order in both columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def sort_dates_in_array(entry):\n",
    "    try:\n",
    "        # Convert string dates to datetime objects for sorting\n",
    "        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n",
    "        # Sort the items based on datetime conversion\n",
    "        sorted_items = sorted(items, key=lambda x: datetime.strptime(x, '%b %Y') if ' ' in x else datetime.strptime(x, '%m/%Y') if '/' in x else datetime.strptime(x, '%Y-%m'))\n",
    "        return sorted_items\n",
    "    except:\n",
    "        return entry  # If any error occurs, return the original entry\n",
    "\n",
    "# Apply the sorting function to both start_dates and end_dates\n",
    "df['start_dates'] = df['start_dates'].apply(sort_dates_in_array)\n",
    "df['end_dates'] = df['end_dates'].apply(sort_dates_in_array)\n",
    "from datetime import datetime\n",
    "\n",
    "def sort_dates_in_array(entry):\n",
    "    try:\n",
    "        # Convert string dates to datetime objects for sorting\n",
    "        items = ast.literal_eval(entry) if isinstance(entry, str) else entry\n",
    "        # Sort the items based on datetime conversion\n",
    "        sorted_items = sorted(items, key=lambda x: datetime.strptime(x, '%b %Y') if ' ' in x else datetime.strptime(x, '%m/%Y') if '/' in x else datetime.strptime(x, '%Y-%m'))\n",
    "        return sorted_items\n",
    "    except:\n",
    "        return entry  # If any error occurs, return the original entry\n",
    "\n",
    "# Apply the sorting function to both start_dates and end_dates\n",
    "df['start_dates'] = df['start_dates'].apply(sort_dates_in_array)\n",
    "df['end_dates'] = df['end_dates'].apply(sort_dates_in_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_experience(start_dates, end_dates):\n",
    "    # Check for 'unknown' in strings\n",
    "    if isinstance(start_dates, str) and start_dates.lower() == 'unknown':\n",
    "        return 'unknown'\n",
    "    if isinstance(end_dates, str) and end_dates.lower() == 'unknown':\n",
    "        return 'unknown'\n",
    "\n",
    "    # Check for 'unknown' inside lists\n",
    "    if isinstance(start_dates, list) and any(str(d).lower() == 'unknown' for d in start_dates):\n",
    "        return 'unknown'\n",
    "    if isinstance(end_dates, list) and any(str(d).lower() == 'unknown' for d in end_dates):\n",
    "        return 'unknown'\n",
    "\n",
    "    # Check for NaNs safely\n",
    "    if isinstance(start_dates, list):\n",
    "        if any(pd.isna(d) for d in start_dates):\n",
    "            return np.nan\n",
    "    elif pd.isna(start_dates):\n",
    "        return np.nan\n",
    "\n",
    "    if isinstance(end_dates, list):\n",
    "        if any(pd.isna(d) for d in end_dates):\n",
    "            return np.nan\n",
    "    elif pd.isna(end_dates):\n",
    "        return np.nan\n",
    "\n",
    "    # Calculate total years of experience\n",
    "    total_years = 0\n",
    "    for start, end in zip(start_dates, end_dates):\n",
    "        try:\n",
    "            start_dt = datetime.strptime(str(start).strip(), '%Y-%m')\n",
    "            end_dt = datetime.strptime(str(end).strip(), '%Y-%m')\n",
    "            total_years += (end_dt - start_dt).days / 365.25\n",
    "        except Exception:\n",
    "            return np.nan  # Invalid date format\n",
    "\n",
    "    return round(total_years, 2) if total_years != 0 else np.nan\n",
    "\n",
    "df['experience_years'] = df.apply(\n",
    "    lambda row: calculate_experience(row['start_dates'], row['end_dates']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Count how many 'unknown' strings are in the experience_years column\n",
    "unknown_experience_count = (df['experience_years']=='unknown').sum()\n",
    "\n",
    "print(\"Total 'unknown' in experience_years:\", unknown_experience_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['start_dates', 'end_dates'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total 'unknown' s are 788 and total 'nan's 112."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "def clean_and_merge_skills(df, col1, col2, col3, new_col='merged_skills'):\n",
    "    # Helper: Parse and clean a single cell\n",
    "    def parse_and_clean(cell):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(cell)\n",
    "        except Exception:\n",
    "            return []\n",
    "\n",
    "        def flatten(x):\n",
    "            if isinstance(x, list):\n",
    "                return [item for sub in x for item in flatten(sub)]\n",
    "            return [x]\n",
    "\n",
    "        flat = flatten(parsed)\n",
    "        cleaned = [s.strip().lower() for s in flat if isinstance(s, str)]\n",
    "        return cleaned\n",
    "\n",
    "    # Helper: Check if the list only contains generic skill patterns\n",
    "    def is_generic_skills_list(skill_list):\n",
    "        pattern = re.compile(r'^skill\\s*\\d+$')\n",
    "        return all(pattern.match(s) for s in skill_list) and len(skill_list) > 0\n",
    "\n",
    "    # Clean both columns\n",
    "    cleaned_col1 = df[col1].apply(parse_and_clean)\n",
    "    cleaned_col2 = df[col2].apply(parse_and_clean)\n",
    "    cleaned_col3 = df[col3].apply(parse_and_clean)\n",
    "\n",
    "    # Merge and deduplicate\n",
    "    df[new_col] = [\n",
    "        list(dict.fromkeys(c1 + c2 + c3)) for c1, c2, c3 in zip(cleaned_col1, cleaned_col2, cleaned_col3)\n",
    "    ]\n",
    "\n",
    "    # Remove generic skill lists\n",
    "    df[new_col] = df[new_col].apply(lambda skills: [] if is_generic_skills_list(skills) else skills)\n",
    "\n",
    "    # Drop original columns\n",
    "    df.drop(columns=[col1, col2, col3], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "clean_and_merge_skills(df, 'skills', 'related_skils_in_job', 'certification_skills', new_col='merged_skills')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skills Required "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_skills_required_column(df):\n",
    "    \n",
    "    def process_skill_entry(entry):\n",
    "        if pd.isna(entry) or entry == \"\":\n",
    "            return []\n",
    "        \n",
    "        # Split by newlines and filter out empty strings\n",
    "        skills = [s.strip() for s in entry.split('\\n') if s.strip()]\n",
    "        \n",
    "        # Clean each skill\n",
    "        cleaned_skills = []\n",
    "        for skill in skills:\n",
    "            # Remove bullet points and other unwanted characters\n",
    "            skill = skill.replace('•', '').strip()\n",
    "            if skill:  # Only add non-empty skills\n",
    "                cleaned_skills.append(skill)\n",
    "        \n",
    "        # Remove duplicates while preserving order\n",
    "        seen = set()\n",
    "        unique_skills = [x for x in cleaned_skills if not (x in seen or seen.add(x))]\n",
    "        \n",
    "        return unique_skills\n",
    "    \n",
    "    # Apply the processing function to the skills_required column\n",
    "    df['skills_required_list'] = df['skills_required'].apply(process_skill_entry)\n",
    "\n",
    "    # Drop the original column\n",
    "    df.drop(columns=['skills_required'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "new_df = preprocess_skills_required_column(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Position Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the model once globally\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Text normalization: strip spaces, lowercase everything\n",
    "def normalize_text(text):\n",
    "    return text.strip().lower()\n",
    "\n",
    "# Main function to encode job titles\n",
    "def encode_job_titles(df, column_name='job_position_name', output_column='job_position_embedding'):\n",
    "    \"\"\"\n",
    "    Encode normalized job titles into dense vectors and store in a new column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with job titles\n",
    "        column_name (str): Name of the column to encode\n",
    "        output_column (str): Name of the column to store embeddings\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Modified DataFrame with added embedding column\n",
    "    \"\"\"\n",
    "    job_titles = df[column_name].fillna(\"\").astype(str).apply(normalize_text).tolist()\n",
    "    embeddings = model.encode(job_titles, show_progress_bar=True)\n",
    "    \n",
    "    # Store embeddings as a list in the new column\n",
    "    df[output_column] = list(embeddings)  # Convert numpy array to list to store it in DataFrame\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Encode the job titles\n",
    "df = encode_job_titles(df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7209104,
     "sourceId": 11499479,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
